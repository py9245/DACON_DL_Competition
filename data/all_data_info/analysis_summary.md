# `analysis_summary.json` 설명

- **생성 배경**: `C:\Users\SSAFY\Desktop\yusin\DACON_DL_Competition\data` 디렉터리와 하위 폴더의 CSV를 최대 300행까지 스캔해 구조·결측·샘플 값을 빠르게 점검하기 위해 만들었습니다.
- **파일 형식**: JSON 배열. 각 원소는 하나의 CSV 파일을 요약한 객체입니다.

## 주요 필드
- `file`: 기준 디렉터리 대비 상대 경로. 분석 대상 CSV가 어디에 있는지 한글 경로 그대로 기록됩니다.
- `encoding`: Pandas로 읽을 때 사용한 인코딩(`utf-8-sig`, `cp949` 등).
- `rows_sampled`: 샘플링한 행 수(최대 300). 파일 행 수가 300보다 적으면 실제 행 수와 일치합니다.
- `columns`: 해당 CSV의 컬럼 개수.
- `dtype_counts`: 샘플 범위에서 발견한 데이터 타입별 컬럼 수(예: `object`, `float64`, `int64`).
- `missing_rate_top`: 결측 비율이 높은 상위 컬럼 10개. `[컬럼명, 결측비율]` 쌍의 리스트로 저장됩니다.
- `sample_values`: 컬럼별 대표 값 최대 5개. 컬럼 수가 50개 이하인 CSV만 포함합니다.

## 활용 포인트
- **EDA 초입**: 대용량 CSV를 모두 열어보지 않고도 구조 및 결측 패턴을 한눈에 확인할 수 있습니다.
- **전처리 설계**: 타입 분포와 결측률을 기반으로 인코딩·결측치 전략을 수립할 때 참고합니다.
- **파일 검증**: 경로·인코딩·컬럼 수가 예상과 다른 경우를 빠르게 찾아낼 수 있습니다.

## 업데이트 방법
1. `analysis_summary.json`을 삭제하거나 다른 이름으로 보관합니다.
2. (필요 시) `python` 명령으로 동일한 스크립트를 다시 실행해 최신 데이터를 반영합니다.
3. 결과가 생성되면 이 문서 내용과 비교하여 변경 사항을 기록합니다.

> 참고: JSON은 UTF-8 인코딩으로 저장되어 있으며, Windows/PowerShell 환경에서도 한글 경로가 깨지지 않도록 `ensure_ascii=False` 옵션으로 직렬화했습니다.
